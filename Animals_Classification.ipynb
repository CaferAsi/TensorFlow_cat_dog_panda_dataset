{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e298da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc054e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaynak_klasoru = 'animals/animals' # https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
    "photo_size = 64\n",
    "resim_boyutu = (photo_size, photo_size)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97a73e",
   "metadata": {},
   "source": [
    "# Veri yükleyicisini oluşturmak için ImageDataGenerator sınıfını kullanabilirsiniz:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99e276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "veri_yukleyici = ImageDataGenerator(rescale=1./255)\n",
    "veri_seti = veri_yukleyici.flow_from_directory(\n",
    "    kaynak_klasoru,\n",
    "    target_size=resim_boyutu,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c89148",
   "metadata": {},
   "source": [
    "# Modeli oluşturmak için Sequential sınıfını kullanabilirsiniz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95465fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(photo_size, photo_size, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78d45b",
   "metadata": {},
   "source": [
    "# Eğitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917d9cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 13s 254ms/step - loss: 0.8619 - accuracy: 0.5283\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.7212 - accuracy: 0.6270\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 14s 286ms/step - loss: 0.6204 - accuracy: 0.6860\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.6039 - accuracy: 0.6957\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 14s 292ms/step - loss: 0.5702 - accuracy: 0.7177\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 13s 270ms/step - loss: 0.5275 - accuracy: 0.7477\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.4708 - accuracy: 0.7793\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 13s 273ms/step - loss: 0.4147 - accuracy: 0.8113\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 13s 274ms/step - loss: 0.3694 - accuracy: 0.8403\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 13s 272ms/step - loss: 0.3330 - accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b19237d4c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "model.fit(veri_seti, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9990573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d739ce9",
   "metadata": {},
   "source": [
    "## modeli model.h5 isiyle kaydedelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f09ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d169cc5",
   "metadata": {},
   "source": [
    "# TestKodu\n",
    "* 1-kutuphane Ekleme\n",
    "* 2- modelin yüklenmesi\n",
    "* 3-test verisi okunması\n",
    "* 4- resimleri  tek tek istenilen formata dönüştürüp model ile tahminin yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566e2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Eğitilmiş modelinizi yükleyin\n",
    "model = load_model( 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f13cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(epochs = 10,photo_size = 64,batch_size = 64):\n",
    "    kaynak_klasoru = 'animal' # https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
    "    resim_boyutu = (photo_size, photo_size)\n",
    "    \n",
    "    veri_yukleyici = ImageDataGenerator(rescale=1./255)\n",
    "    veri_seti = veri_yukleyici.flow_from_directory(\n",
    "        kaynak_klasoru,\n",
    "        target_size=resim_boyutu,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(photo_size, photo_size, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    model.fit(veri_seti, epochs=epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19da40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model,show=False,folderName=\"dogs\"):\n",
    "    \n",
    "    test_folder = f'test_images/{folderName}'  # Test verilerinizin bulunduğu klasör yolu\n",
    "\n",
    "    ppp=[]\n",
    "\n",
    "    # Test resimlerinizi yükleyin ve tahmin yapın\n",
    "    for filename in os.listdir(test_folder):\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((photo_size, photo_size))  # Resmi 64x64 boyutuna yeniden boyutlandırın\n",
    "        img = np.array(img) / 255.0  # Resimleri [0, 1] aralığında ölçeklendirin\n",
    "        img = np.expand_dims(img, axis=0)  # Girdi tensörü boyutunu (1, 64, 64, 3) yapın\n",
    "\n",
    "        # Tahmin yapın\n",
    "        pred = model.predict(img)\n",
    "        prediction = np.argmax(pred, axis=1)\n",
    "\n",
    "        # Tahmin sonucunu yazdırın\n",
    "        if show:\n",
    "            print(f\"{filename}: {prediction}\") \n",
    "\n",
    "        # yazdırmak yerine sonucu listeye ekleyip değerlendirlim\n",
    "        ppp.append(prediction)\n",
    "        \n",
    "        \n",
    "\n",
    "    return ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25562934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "dog.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00001.jpg: [1]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00002.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00003.jpg: [0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00004.jpg: [0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "dogs_00005.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00006.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00007.jpg: [0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00008.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00009.jpg: [1]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00010.jpg: [0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00011.jpg: [1]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00012.jpg: [1]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00013.jpg: [1]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00014.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00015.jpg: [0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00016.jpg: [0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00017.jpg: [0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00018.jpg: [0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00019.jpg: [1]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00020.jpg: [0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00021.jpg: [0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00022.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00023.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00024.jpg: [1]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "dogs_00025.jpg: [0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "dogs_00026.jpg: [1]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00027.jpg: [0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "dogs_00028.jpg: [1]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "dogs_00029.jpg: [1]\n",
      "tahim sonucu \n",
      "  kedi : 12 \n",
      "  kopek : 18 \n",
      "  panda : 0 \n",
      "  toplam tahmin30\n",
      "doğruluk 0.6\n"
     ]
    }
   ],
   "source": [
    "a=TestModel(model,True,\"dogs\")\n",
    "print(f\"tahim sonucu \\n  kedi : {a.count(0)} \\n  kopek : {a.count(1)} \\n  panda : {a.count(2)} \\n  toplam tahmin{len(a)}\")\n",
    "print(\"doğruluk\",a.count(1) /len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35d941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "tahim sonucu \n",
      "  kedi : 12 \n",
      "  kopek : 2 \n",
      "  panda : 0 \n",
      "  toplam tahmin14\n",
      "doğruluk 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "a=TestModel(model,False,\"cats\")\n",
    "print(f\"tahim sonucu \\n  kedi : {a.count(0)} \\n  kopek : {a.count(1)} \\n  panda : {a.count(2)} \\n  toplam tahmin{len(a)}\")\n",
    "print(\"doğruluk\", (a.count(0)/len(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afd6bd68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 10s 304ms/step - loss: 0.6963 - accuracy: 0.5026\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 0.6856 - accuracy: 0.5751\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 9s 294ms/step - loss: 0.6618 - accuracy: 0.5858\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.6359 - accuracy: 0.6272\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.6019 - accuracy: 0.6691\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.5707 - accuracy: 0.6859\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.5282 - accuracy: 0.7416\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 11s 363ms/step - loss: 0.4917 - accuracy: 0.7584\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 0.4731 - accuracy: 0.7712\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 9s 300ms/step - loss: 0.3979 - accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "#myModel=TrainModel()\n",
    "#a=TestModel(myModel,False,\"dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebdf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
